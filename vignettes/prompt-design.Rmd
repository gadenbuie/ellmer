---
title: "Prompt design"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Prompt design}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = elmer:::openai_key_exists() && elmer:::anthropic_key_exists()
)
options(elmer_seed = 1337)
```

In this vignette, you'll learn the bascis of writing an LLM prompt, i.e. the text that you send to an LLM asking it to do a job for you. If you've never written a prompt before, a good to way to think about it is as writing a set of instructions for a technically skilled but busy human. You'll need to clearly and concisely state what you want, resolve any potential ambiguities that are likely to arise, and provide a few examples. Don't expect to write the perfect prompt on your first attemp. You'll need to iterate a few times, but in my experience, this iteration is very worthwhile because it forces you to clarify your understanding of the problem.

As well as the general advice in this vignette, it's also a good idea to read the specific advice for the model that you're using. Here are some pointers to the prompt engineering guides for a few popular models:

* [Claude](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)
* [OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)
* [Gemini](https://ai.google.dev/gemini-api/docs/prompting-intro)

If you have a claude account, you can use its <https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator>. This prompt generator has been specifically tailored for Claude, but I suspect it will help many other LLMs, or at least give you some ideas as to what else you might want to include in your prompt.

```{r setup}
library(elmer)
```

## Mechanics

Store in a separate file using markdown. Because prompts can be quite long, we suggest writing them in markdown. LLMs, like humans, appear to find markdown to be quite readable. That way you can use headers to divide up the prompt, and other tools like itemised lists to enumerate multiple options.

Store them in git.

`prompt.md` is a good name if you only have one. If you have multiple, give them informative names. If you're writing a package, put it in `inst/prompts`.

Use glue syntax (but with `{{ }}`) to interpolate in data.

Supported by `interpolate_file()` that makes it easy to read in file.

 and build up a small set of challenge examples that you can use to verify that the prompt does what you expect. (Eventually, you might want to formally __evaluate__ different prompts for the problem you're tackling, but that's currently outside the scope of elmer.)

* Shiny assistant prompt
* Hadley recipe prompt
* Sidebot
* https://github.com/simonpcouch/pal/tree/main/inst/prompts

However, for the purposes of this vignette, we'll keep the prompts fairly short and just use a string so you can more easily read them.

## Code generation

Let's explore prompt design for a simple code generation task:

```{r}
question <- "
  How can I compute the mean and median of variables a, b, c, and so on,
  all the way up to z, grouped by age and sex.
"
```

I'll use

### Basic flavour

When I don't provide any context, I get answers in a couple of languages:

```{r}
chat <- chat_claude()
chat$chat(question)
```

So I can specify that I want the LLM to be an R programmer:

```{r}
chat <- chat_claude(system_prompt = "
  You are an expert R programmer.
")
chat$chat(question)
```

Since I'm mostly interested in the code, I ask it to drop the explanation and the sample data:

```{r}
chat <- chat_openai(system_prompt = "
  You are an expert R programmer.
  Just give me the code without any text explanation.
  Don't generate any sample data.
")
chat$chat(question)
```

In this case, I seem to mostly get tidyverse code. But if you want a different style, you can ask for it:

```{r}
chat <- chat_claude(system_prompt = "
  You are an expert R programmer who prefers data.table.
  Just give me the code. I don't want any explanation or sample data.
")
chat$chat(question)
```

```{r}
chat <- chat_claude(system_prompt = "
  You are an expert R programmer who prefers base R.
  Just give me the code. I don't want any explanation or sample data.
")
chat$chat(question)
```

### Be explicit

```{r}
chat <- chat_openai(system_prompt = "
  You are an expert R programmer.
  Just give me the code. I don't want any explanation or sample data.
  Follow the tidyverse style guide:
  * Spread long function calls across multiple lines.
  * Where needed, always indent function calls with two spaces.
  * Always use double quotes for strings.
  Use the base pipe, `|>`, not the magrittr pipe `%>%`.
")
chat$chat(question)
```

```{r}
chat <- chat_openai(system_prompt = "
  You are an an expert R programmer and a warm and supportive teacher.
  Help me understand the code you produce by explaining each function call with
  a brief comment. Add more details for more complicated calls.
  Just give me the code. I don't want any explanation or sample data.
")
chat$chat(question)
```

### Teach it about new features

```{r}
chat <- chat_openai(system_prompt = "
  You are an expert R programmer.
  Just give me the code; no explanation in text.
  Use the `.by` argument rather than `group_by()`.
  dplyr 1.1.0 introduced per-operation grouping with the `.by` argument.
  e.g., instead of:

  transactions |>
    group_by(company, year) |>
    mutate(total = sum(revenue))

  write this:
  transactions |>
    mutate(
      total = sum(revenue),
      .by = c(company, year)
    )
")
chat$chat(question)
```

Note, however, there is a cost to too many examples: the LLM can get fixated on them, and fail to incorrectly generalise to new problems.

## Structured data

You'll also hear this called single-shot or multi-shot prompting.

Note, however, there are some

- **Goal:** Extract ingredient list from recipe and return in a structured format.

- Example user input:

  ```
  In a large bowl, cream together 1 cup of softened unsalted butter and ½ cup of white sugar until smooth. Beat in 1 egg and 1 teaspoon of vanilla extract. Gradually stir in 2 cups of all-purpose flour until the dough forms. Finally, fold in 1 cup of semisweet chocolate chips. Drop spoonfuls of dough onto an ungreased baking sheet and bake at 350°F (175°C) for 10-12 minutes, or until the edges are lightly browned. Let the cookies cool on the baking sheet for a few minutes before transferring to a wire rack to cool completely. Enjoy!
  ```

### System prompt 1: just instructions

```
The user input contains a recipe. Extract a list of ingredients and return it in JSON format.
```

Assistant response:

```{.json}
{
  "ingredients": [
    "1 cup of softened unsalted butter",
    "½ cup of white sugar",
    "1 egg",
    "1 teaspoon of vanilla extract",
    "2 cups of all-purpose flour",
    "1 cup of semisweet chocolate chips"
  ]
}
```

### System prompt 2: detailed description of output

```
The user input contains a recipe. Extract a list of ingredients and return it in JSON format. It should be an array of objects, where each object has keys `ingredient`, `quantity`, and `unit`. Put each object on one line of output.
```

Assistant response:

```{.json}
[
    {"ingredient": "unsalted butter", "quantity": 1, "unit": "cup"},
    {"ingredient": "white sugar", "quantity": 1/2, "unit": "cup"},
    {"ingredient": "egg", "quantity": 1, "unit": "large"},
    {"ingredient": "vanilla extract", "quantity": 1, "unit": "teaspoon"},
    {"ingredient": "all-purpose flour", "quantity": 2, "unit": "cups"},
    {"ingredient": "semisweet chocolate chips", "quantity": 1, "unit": "cup"}
]
```

### System prompt 3: one-shot example

````
The user input contains a recipe. Extract a list of ingredients and return it in JSON format.

Example Output:

```json
[
    { "ingredient": "Flour", "quantity": 1, "unit": "cup" },
    { "ingredient": "Vegetable oil", "quantity": 0.5, "unit": "tsp" },
    { "ingredient": "Onion", "quantity": 1, "unit": null },
]
```
````

Assistant response:

```{.json}
[
    { "ingredient": "Unsalted butter", "quantity": 1, "unit": "cup" },
    { "ingredient": "White sugar", "quantity": 0.5, "unit": "cup" },
    { "ingredient": "Egg", "quantity": 1, "unit": null },
    { "ingredient": "Vanilla extract", "quantity": 1, "unit": "teaspoon" },
    { "ingredient": "All-purpose flour", "quantity": 2, "unit": "cups" },
    { "ingredient": "Semisweet chocolate chips", "quantity": 1, "unit": "cup" }
]
```
